# 第5章：稳定性

*Edit: 李一飞，王茂霖，Hao ZHAN，赵志民*

---

本章的内容围绕学习理论中的稳定性而展开。在第四章中，我们给予不同的复杂度度量方式来给出了一些泛化界，这些泛化界与特定的算法无关。因此，可能就有人会问，对特定算法的性质进行分析能否得到更好的学习保障？这种对某一算法的分析能否扩展到其他有相似性质的学习算法上？

本章针对于这些问题进行了解答，应用算法稳定性来推导出了依赖于算法的学习保证。



## 1.【概念补充】留一风险

**P90**提到留一风险（leave-one-out risk）。

所谓留一风险，就是依次计算从数据集中剔除某一数据后所训练出来的模型与该被剔除出的数据之间的风险。它的本质就是保证用于风险测试的数据不会被加入到训练数据之中。类似于模型选择时的留一验证。



## 2.【证明补充】均匀稳定性与泛化上界

**P92**中，定理5.1讨论了**均匀稳定性**与泛化性的关系。这里重新梳理一下均匀稳定性和泛化性究竟在哪一步证明过程中得以关联。

### （1）证明简述

根据读者几章阅读的经验，想必大家对这些不等式有些熟门熟路了，见到题目中有 $ln$ 有根号等等便能够意识到这里又是关于指数函数的不等式然后反解风险 $\epsilon$ 了。这里是希望通过样本的稳定性推出关于风险的泛化性，因此我们要证明的时候必须想办法将风险之间的差距转化为损失函数之间的风险。

由于定理中给出的替换样本 $\beta$-均匀稳定性和移除样本 $\gamma$-均匀稳定性是非常强的条件，对于任意的数据集 D 和任意的样本 **z** 成立，因此我们很容易可以得到关于*经验风险和泛化风险差距*（即 $\Phi(D)$） 的估计式。

我们通过对损失函数的差求和平均即是风险 (Risk) 的差距，因为替换样本 $\beta$-均匀稳定性满足对任意 **z** 成立，因此我们得到 (5.22) 与 (5.23) 式。使用 McDiarmid 不等式便可以得到关于*经验风险与泛化风险的差距*（即 $\Phi(D)$） 超过其平均值至少 $\epsilon$ 的概率。即：
$$
P(\phi(D)\geq\mathbb{E}[\Phi(D)]+\epsilon)\leq exp(\frac{-2m\epsilon^2}{(2m\beta+M)^2})
$$
之后进行简单的放缩估计便可以得到最终的式子
$$
P(R(\mathcal{L_D})-\hat R(\mathcal{L_D})\geq\beta+\epsilon)\leq exp(\frac{-2m\epsilon^2}{(2m\beta+M)^2})
$$

值得注意的是，（5.22）中最后一步不等式的推导其实是省略了一步，即：
$$
\begin{aligned}
&\frac{|\ell(\mathfrak{L}_D,z_i)-\ell(\mathfrak{L}_{D^{i,z'_i}},z'_i)|}{m}+\sum_{j\neq i}\frac{|\ell(\mathfrak{L}_D,z_j)-\ell(\mathfrak{L}_{D^{i,z'_i}},z_j)|}{m}\\
&\le \frac{M}{m}+\frac{m-1}{m}\beta \\
&\le \frac{M}{m}+\beta
\end{aligned}
$$
之所以这么做，是因为在样本量$m$较大的时候，$\frac{\beta}{m}$的大小可以忽略不计，因此在结论中并没有出现这一项。

另外，（5.23）也省略了一步，即：
$$
|E_{z\sim\mathcal{D}}[\ell(\mathfrak{L}_D,z)-\ell(\mathfrak{L}_{D^{i,z'_i}},z)]|\le E_{z\sim\mathcal{D}}[|\ell(\mathfrak{L}_D,z)-\ell(\mathfrak{L}_{D^{i,z'_i}},z)|]\le E_{z\sim\mathcal{D}}[\beta]=\beta
$$

最后，关于移除样本 $\gamma$-均匀稳定性（5.18）的证明用到了（5.14）的结论，所以我们才得以在不等式中构造出类似于$2m\beta$的$4m\gamma$形式，其他推理步骤几乎与（5.17）完全一致。

### （2）均匀稳定性与泛化性的关系

在这个证明过程中，有多处涉及到了损失函数作差放缩，即替换样本 $\beta$-均匀稳定性，但实际上多数情况下使用只是为了放缩得到更简单的式子，只有在 (5.24) 与 (5.25) 处主要体现了稳定性与泛化性的关系。

在 (5.24) 处通过替换样本的稳定性，我们可以得到*经验风险与泛化风险的差距*（即 $\Phi(D)$ ) 在替换样本前后的风险能够被上界 $2\beta+M/m$ 控制住，根据 McDiarmid 不等式的描述，如果实值函数关于变量的替换如果具有较好的稳定性，那么该实值函数总有与期望的差距同样被上界控制住。（简单描述就是如果实值函数替换一个变量之后风险不大，那么无论怎么替换风险都不会过大，因此实值函数取值总会在一定范围内，从而总和均值（即期望）相差不大。）。因此在 (5.25) 处我们能够得到*经验风险与泛化风险的差距*（即 $\Phi(D)$ ) 同样有了上界，自然我们通过简单的放缩就可以获得一个常数上界，得到泛化风险的上界。



## 3.【证明补充】假设稳定性与泛化上界

**P94**中，定理5.2讨论了**假设稳定性**与泛化性的关系。这里重新梳理一下假设稳定性和泛化性究竟在哪一步证明过程中得以关联。

### （1）证明简述

证明是关于 $R(\mathcal{L_D})-\hat R(\mathcal{L_D})$ 的平方平均，这是因为假设稳定性是比较弱的条件，只能保证风险的期望被上界控制，因此这里只能得到关于期望的不等式。同样的，因为不涉及到概率与置信度，因此我们并不需要复杂的不等式，只需要使用简单的放缩便能够得到答案。

单纯从证明的角度来讲，里面可能最不容易理解的一点是反复出现于（5.30）至（5.33）中关于变量$z$之间的替换。
根据独立同分布假设，即$\forall i,j\in \mathbb{N}^+,z,z',z_i,z_j\sim\mathcal{D}$，我们可以任意交换$z,z',z_i,z_j$的顺序，而期望值并不改变。
例如，在（5.30）的第一步推导中，不失一般性地用$z_1,z_2$替代了$z_i,z_j$，因此原期望值之和得以化简为只跟$z_1,z_2$有关的期望值。
搞清楚这一点，任何时候出现关于变量$z$之间的替换都不会让人感到困惑了，其中就包括了定理5.3证明中（5.35）的第二步推导。

另外，在（5.32）的第一步推导中，利用到了不等式$E(X+Y)\le E(|X|)+E(|Y|)$。这种在期望缩放中运用绝对值不等式的处理方式在全书中并不少见，算是非常实用的小技巧了。

### （2）泛化性与假设稳定性

这里实际上并不是简单的泛化界的关系，实际上给出了经验风险与泛化风险的差距的平方平均的界，这是因为假设稳定性并不是非常强的结论，事实上假设稳定性就是为了放松均匀稳定性这个较强的条件得到的。



## 4.【证明补充】过拟合与欠拟合

过拟合和欠拟合是泛化性研究的非常重要的互补概念。我们知道经验风险与泛化风险的差距较大的时候，会发生过拟合；反之，泛化风险与经验风险的差距较大的时候，则发生欠拟合。因此我们希望能够在算法设计的时候，尽可能地最小化泛化风险与经验风险的差距。

**P96**中，定理5.3从算法稳定性的角度提出了防止过拟合的可行方案：当替换训练集的单个样本时，算法的输出函数不发生较大变化时，我们认为学习算法$\mathfrak{L}$是稳定的，否则就需要重新进行训练。该方法论也适用于欠拟合的情况，不过在实际应用中，算法发生欠拟合的情况较少，因此我们更多地关注过拟合的预防。



## 5.【证明补充】稳定性与可学性

**P97**中，定理5.4涉及了稳定性与可学性之间的转换。这里通过对定理5.4进行梳理，分析稳定性和可学性在哪一步证明过程中得以关联。

### （1）证明简述

这里要回顾一下不可知 PAC 可学的概念：

对所有分布 $\mathcal{D}$ ，若存在学习算法 $\mathcal{L}$ 与多项式函数 $poly(\cdot,\cdot,\cdot,\cdot)$ ，使得对于任何 $m\geq poly(1/\epsilon,1/\delta,size(\mathbf{x}),size(c))$ $\mathcal{L}$ 输出的假设能满足
$$
   	P\big(E(h)-min_{h'\in\mathcal{H}}E(h')\leq\epsilon\big)\geq1-\delta
$$

这里的证明实际上就是利用经验风险与泛化风险之间的联系构造出（5.39），分而治之地讨论了不同场景下的稳定性与可学性关系。

其中，泛化风险与经验风险之差（5.40）可以根据定理5.1改写成：对于任意的$\delta\in(0,1)$，以至少$1-\delta$的概率有：
$$
R(\mathfrak{L}_D)-\hat R(\mathfrak{L}_D)\le \frac{1}{m}+(2m\beta+M)\sqrt{\frac{ln(1/\delta)}{2m}}
$$
参考**P95**对于$lim_{m\rightarrow +\infty}m\beta$讨论，只要满足$lim_{m\rightarrow +\infty}m\beta\lt\infty$这个条件，算法的泛化性能就可以得到保障，因此我们应确保$\beta$的取值不要太大。
在此定理中，我们选取$\beta=1/m$，此时上式简化为：
$$
R(\mathfrak{L}_D)-\hat R(\mathfrak{L}_D)\le \frac{1}{m}+(2+M)\sqrt{\frac{ln(1/\delta)}{2m}}
$$

在处理ERM算法情况下泛化风险与经验风险之差（5.42）时，原书中有一处小错误，不过对于最终结论的影响不是很大。这里我们给出正确的推导过程：
根据$\ell(\mathfrak{L}_D,z)\in[0,M]$，我们可以得到$\hat R \in [0,M]$，又因为$R(h^*)=E_{\mathcal{D}}(\hat R(h^*))$，此时根据Hoeffding不等式（1.30），可知至少以$1-\delta$的概率有：
$$
\hat R(h^*)-R(h^*)\le M\sqrt{\frac{ln(1/\delta)}{2m}}
$$
此时结合（5.39）至（5.42）可知，得知至少以$1-\delta$的概率有：
$$
R(\mathfrak{L}_D)-R(h^*)\le \frac{1}{m}+(2+M)\sqrt{\frac{ln(1/\delta)}{2m}}+M\sqrt{\frac{ln(1/\delta)}{2m}}
$$
此时（5.44）变为：
$$
\epsilon=\frac{1}{m}+(1+M)\sqrt{\frac{2ln(1/\delta)}{m}}
$$
令$m'=\sqrt m$，则可以将上式转化为关于$m'$的一元二次方程：
$$
\epsilon m'^2-Am'-1=0
$$
其中$A=(1+M)\sqrt{2ln(1/\delta)}$，根据求根公式可得：
$$
m'=\frac{A\pm\sqrt{A^2+4\epsilon}}{2\epsilon} = O(\frac{1}{\epsilon}\sqrt{ln(\frac{1}{\delta})})
$$
至此，我们得到了$m$的渐进复杂度：
$$
m=m'^2=O(\frac{1}{\epsilon^2}ln(\frac{1}{\delta}))
$$
接下来的推导便水到渠成了。

### （2）稳定性与可学习性

这里之所以只能到达不可知 PAC 可学是因为泛化界只能够以概率达到，不能保证在任何的函数空间都达到上界以下，因此只能得到稳定性与不可知 PAC 可学性的关系。

事实上这里的稳定性与可学习性的关系类似于第四章我们讲到的泛化界与可学习性的关系，即在拥有一直上界之后通过 ERM 算法得到最小经验风险函数，便得到了更为细致的界。事实上这里稳定性与可学习性联系的时候便是使用了均匀稳定性带来的**泛化上界**与后面 ERM 的结果联合作用得到了可学习性。



## 6.【概念补充】稳定性的适用性

细心的读者会发现这里的稳定性只在某些条件下才能够使用，这里我们对这些条件进行一个总结。
首先，本章的分析假设输出函数$\mathfrak{L}_D$与训练集$D$的顺序无关，但这在实际中并不一定成立，例如在随机梯度下降算法中，训练集的顺序会影响最终的输出函数，因此这里的稳定性并不适用于随机梯度下降算法。

另外，在样本扰动的分析中，我们几乎没有对新增样本这一情况进行单独讨论。这是因为稳定性的要求在数据或者概念发生漂移的情况下不一定成立，因为这时候训练集的分布与真实分布已不再一致。而本章在研究训练集$D$的扰动对算法$\mathfrak{L}_D$输出函数的影响时，希望经验风险的变化尽可能地小，这恰好与[增量学习](https://en.wikipedia.org/wiki/Incremental_learning)的目标有一些抵触。
持续学习关注模型的可塑性，即在旧场景中训练的模型是否能通过优化在新场景中表现优异，因此我们在真实场景中需要平衡学习算法的可塑性与稳定性。
