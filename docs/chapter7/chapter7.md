# 第7章：收敛率

*Edit: 李一飞，赵志民*

---

本章的内容围绕学习理论中的收敛率（convergence rate）展开。具体来说，将会考察确定优化下的收敛率问题，以及随机优化下的收敛率问题，并在最后分析支持向量机的实例。

## 1.【概念补充】算法收敛率

在算法分析中，收敛率是指迭代算法逼近解或收敛到最优或期望结果的速度，它衡量算法在减小当前解与最优解之间差异方面的快慢。以下是几种常见的衡量算法收敛速度的方法：

1. 误差缩减：如果算法的目标是最小化误差指标或最大化性能指标，则可以追踪每次迭代中的误差减少或性能改进情况。可以通过将误差或性能指标与迭代次数绘制成图形并分析趋势来衡量收敛速度，陡峭的下降或改进表示收敛速度更快。

2. 残差分析：某些算法（例如用于线性系统的迭代求解器或优化算法）通过减小当前解与期望解之间的残差来工作。在这种情况下，可以在每次迭代中追踪残差并观察其下降速度，残差的迅速减小表明收敛速度更高。

3. 变化速率：另一种方法是测量连续迭代之间目标函数或误差指标的变化率。可以通过计算每个步骤中指标值的绝对或相对差异来实现，变化率的快速下降表示收敛速度更快。

4. 收敛准则：许多算法使用收敛准则确定何时停止迭代。这些准则可以基于目标函数、误差指标或变化速率的预定义阈值，满足收敛准则所需的迭代次数可作为收敛速度的间接衡量指标。

5. 时间复杂度分析：在某些情况下，可以分析算法的时间复杂度来估计其收敛速度。时间复杂度提供了算法运行时间随输入规模增长的理解，通常时间复杂度较低的算法通常收敛速度更快。

在本章中，
